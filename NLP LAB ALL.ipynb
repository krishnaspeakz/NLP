{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4a5741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kittu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07dddcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Natural', 'Language', 'Processing', 'is', 'fascinating', '!']\n",
      "Stems: ['natur', 'languag', 'process', 'is', 'fascin', '!']\n",
      "Pos tags: [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('is', 'VBZ'), ('fascinating', 'VBG'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "#1 Word Analysis\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "from nltk.stem import PorterStemmer as ps\n",
    "from nltk import *\n",
    "text = \"Natural Language Processing is fascinating!\"\n",
    "token = wt(text)\n",
    "print(\"Tokens:\",wt(text))\n",
    "\n",
    "stemmer = ps()\n",
    "words = [stemmer.stem(x) for x in token]\n",
    "print(\"Stems:\",words)\n",
    "\n",
    "print(\"Pos tags:\", pos_tag(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5895bd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Natural', 'Language', 'Processing', 'is', 'fascinating', '!']\n",
      "Stems: ['natur', 'languag', 'process', 'is', 'fascin', '!']\n",
      "lemma: ['Natural', 'Language', 'Processing', 'is', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "#Morphology\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "from nltk.stem import PorterStemmer as ps\n",
    "from nltk.stem import WordNetLemmatizer as wn\n",
    "from nltk import *\n",
    "text = \"Natural Language Processing is fascinating!\"\n",
    "token = wt(text)\n",
    "print(\"Tokens:\",wt(text))\n",
    "\n",
    "stemmer = ps()\n",
    "words = [stemmer.stem(x) for x in token]\n",
    "print(\"Stems:\",words)\n",
    "\n",
    "lem = wn()\n",
    "wl = [lem.lemmatize(x) for x in token]\n",
    "print(\"lemma:\",wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ec6c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-grams: [('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'is'), ('Processing', 'is', 'fascinating'), ('is', 'fascinating', 'and'), ('fascinating', 'and', 'powerful'), ('and', 'powerful', '.')]\n"
     ]
    }
   ],
   "source": [
    "#N-Grams\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def gen(text, n):\n",
    "    words = word_tokenize(text)\n",
    "    n_grams = list(ngrams(words, n))\n",
    "    return n_grams\n",
    "\n",
    "text = \"Natural Language Processing is fascinating and powerful.\"\n",
    "n = 3\n",
    "result = gen(text, n)\n",
    "print(f\"{n}-grams:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e43da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams with Add-One Smoothing: [(('Natural', 'Language'), 0.14285714285714285), (('Language', 'Processing'), 0.14285714285714285), (('Processing', 'is'), 0.14285714285714285), (('is', 'fascinating'), 0.14285714285714285), (('fascinating', 'and'), 0.14285714285714285), (('and', 'powerful'), 0.14285714285714285), (('powerful', '.'), 0.14285714285714285)]\n"
     ]
    }
   ],
   "source": [
    "#N-Grams Smoothing\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "def gen(text, n):\n",
    "    words = word_tokenize(text)\n",
    "    n_grams = list(ngrams(words, n))\n",
    "    freq_dist = FreqDist(n_grams)\n",
    "    vocab_size = len(set(n_grams))\n",
    "    smoothed_n_grams = [(gram, (freq_dist[gram] + 1) / (len(n_grams) + vocab_size)) for gram in n_grams]\n",
    "    return smoothed_n_grams\n",
    "\n",
    "text_to_analyze = \"Natural Language Processing is fascinating and powerful.\"\n",
    "n_value = 2\n",
    "result_ngrams = gen(text_to_analyze, n_value)\n",
    "print(f\"{n_value}-grams with Add-One Smoothing:\", result_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6fbd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Natural', 'Language', 'Processing', 'is', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "#6. WORD TOKENIZER\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "text = \"Natural Language Processing is fascinating!\"\n",
    "token = wt(text)\n",
    "print(\"Tokens:\",wt(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cfdaeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Natural Language Processing is fascinating!.\n",
      "2. Show sensitivity to linguistic phenomena and an ability to model them with formal grammars.\n"
     ]
    }
   ],
   "source": [
    "#7 SENTENCE TOKENIZER\n",
    "from nltk.tokenize import sent_tokenize as st\n",
    "text = \"Natural Language Processing is fascinating!. Show sensitivity to linguistic phenomena and an ability to model them with formal grammars.\"\n",
    "token = st(text)\n",
    "# print(\"Tokens:\",st(text))\n",
    "\n",
    "for i,x in enumerate(token,start = 1):\n",
    "    print(f\"{i}. {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "642e2bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. NLTK is a powerful library for natural language processing.It provides tools for tasks such as tokenization, stemming, and part-of-speech tagging.\n",
      "2. The library is widely used in the field of artificial intelligence.It is a valuable resource for researchers and developers working on NLP projects.\n"
     ]
    }
   ],
   "source": [
    "#8 PARAGRAPH TOKENIZER\n",
    "\n",
    "text = \"\"\" NLTK is a powerful library for natural language processing.It provides tools for tasks such as tokenization, stemming, and part-of-speech tagging.\n",
    "\n",
    "The library is widely used in the field of artificial intelligence.It is a valuable resource for researchers and developers working on NLP projects.\n",
    "\"\"\"\n",
    "\n",
    "para = text.split('\\n\\n')\n",
    "\n",
    "for i,x in enumerate(para,start = 1):\n",
    "    print(f\"{i}. {x.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70cc4dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Categories: 90\n",
      "Categories: ['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee']\n",
      "File IDs in 'crude' category: ['test/14829', 'test/15063', 'test/15200', 'test/15230', 'test/15238']\n",
      "\n",
      "Text of Document (ID: test/14826 ):\n",
      " ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\n",
      "  Mounting trade friction between the\n",
      "  U.S. And Japan has raised fears among many of Asia's exporting\n",
      "  nations that the row could inflict far-reaching economic\n",
      "  damage, businessmen and officials said.\n",
      "      They told Reuter correspondents in Asian capitals a U.S.\n",
      "  Move against Japan might boost protectionist sentiment in the\n",
      "  U.S. And lead to curbs on American imports of their products.\n",
      "      But some exporters said that while the conflict wo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\kittu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#9 Corpora\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "nltk.download('reuters')\n",
    "\n",
    "def load_reuters_corpus():\n",
    "    corpus = reuters\n",
    "    \n",
    "    print(\"Number of Categories:\", len(corpus.categories()))\n",
    "    print(\"Categories:\", corpus.categories()[:10])\n",
    "    print(\"File IDs in 'crude' category:\", corpus.fileids('crude')[:5])\n",
    "    \n",
    "    document_id = 'test/14826'\n",
    "    document_text = corpus.raw(document_id)\n",
    "    print(\"\\nText of Document (ID:\", document_id, \"):\\n\", document_text[:500])\n",
    "\n",
    "load_reuters_corpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aafa6b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse Tree:\n",
      "(S\n",
      "  (NP (Det the) (N man))\n",
      "  (VP\n",
      "    (VP (V saw) (NP (Det a) (N cat)))\n",
      "    (PP (P with) (NP (Det a) (N dog)))))\n"
     ]
    }
   ],
   "source": [
    "#10. .PROBABILISTIC PARSING\n",
    "import nltk\n",
    "from nltk import CFG\n",
    "from nltk.parse import EarleyChartParser\n",
    "\n",
    "pcfg_grammar = CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det N | NP PP | 'John'\n",
    "    Det -> 'the' | 'a'\n",
    "    N -> 'man' | 'dog' | 'cat'\n",
    "    VP -> V NP | VP PP\n",
    "    V -> 'chased' | 'saw'\n",
    "    PP -> P NP\n",
    "    P -> 'with' | 'in'\n",
    "\"\"\")\n",
    "\n",
    "def probabilistic_parsing(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    parser = EarleyChartParser(pcfg_grammar)\n",
    "    for tree in parser.parse(tokens):\n",
    "        print(\"Parse Tree:\")\n",
    "        print(tree)\n",
    "        break\n",
    "        \n",
    "example_sentence = \"the man saw a cat with a dog\"\n",
    "probabilistic_parsing(example_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0111c244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse Tree with Probability: (S\n",
      "  (NP (Det the) (N man))\n",
      "  (VP\n",
      "    (VP (V saw) (NP (Det a) (N cat)))\n",
      "    (PP (P with) (NP (Det a) (N dog)))))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import PCFG\n",
    "from nltk.parse import EarleyChartParser\n",
    "\n",
    "pcfg_grammar = PCFG.fromstring(\"\"\"\n",
    "    S -> NP VP [1.0]\n",
    "    NP -> Det N [0.5] | NP PP [0.4] | 'John' [0.1]\n",
    "    Det -> 'the' [0.6] | 'a' [0.4]\n",
    "    N -> 'man' [0.5] | 'dog' [0.3] | 'cat' [0.2]\n",
    "    VP -> V NP [0.7] | VP PP [0.3]\n",
    "    V -> 'chased' [0.4] | 'saw' [0.6]\n",
    "    PP -> P NP [1.0]\n",
    "    P -> 'with' [0.7] | 'in' [0.3]\n",
    "\"\"\")\n",
    "\n",
    "def probabilistic_parsing(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    parser = EarleyChartParser(pcfg_grammar)\n",
    "    for tree in parser.parse(tokens):\n",
    "        print(\"Parse Tree with Probability:\", tree)\n",
    "        break  \n",
    "\n",
    "example_sentence = \"the man saw a cat with a dog\"\n",
    "probabilistic_parsing(example_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c051fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
